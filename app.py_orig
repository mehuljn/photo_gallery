from flask import Flask, render_template, request, redirect, url_for, flash, send_from_directory, jsonify
from werkzeug.utils import secure_filename
from config import Config
import os
import base64
import requests # Import the requests library

app = Flask(__name__)
app.config.from_object(Config)

# Ollama configuration
OLLAMA_API_BASE_URL = os.environ.get('OLLAMA_API_BASE_URL', 'http://localhost:11434/api')
OLLAMA_MODEL = os.environ.get('OLLAMA_MODEL', 'llava') # Ensure this is a multimodal model you have pulled

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

@app.route('/')
def index():
    # Get a list of all image files in the uploads directory
    image_files = []
    if os.path.exists(app.config['UPLOAD_FOLDER']):
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if allowed_file(filename):
                image_files.append(filename)
    # Pass the list of image filenames to the template
    return render_template('index.html', image_files=image_files)

@app.route('/upload', methods=['GET', 'POST'])
def upload_file():
    if request.method == 'POST':
        # Check if the post request has the file part
        if 'file' not in request.files:
            flash('No file part')
            return redirect(request.url)
        file = request.files['file']
        # If the user does not select a file, the browser submits an
        # empty file without a filename.
        if file.filename == '':
            flash('No selected file')
            return redirect(request.url)
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            try:
                os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True) # Ensure directory exists
                file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
                flash('Image successfully uploaded')
                return redirect(url_for('index'))
            except Exception as e:
                flash(f'Error uploading file: {e}')
                return redirect(request.url)
        else:
            flash('Allowed image types are png, jpg, jpeg, gif')
            return redirect(request.url)
    return render_template('upload.html') # You'll create this template in a moment

@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/chat_with_llm', methods=['POST'])
def chat_with_llm():
    data = request.json
    user_query = data.get('query')
    image_data_b64 = data.get('image') # This is the base64 encoded image string

    if not user_query or not image_data_b64:
        return jsonify({'error': 'Missing query or image data'}), 400

    try:
        # Decode base64 image data
        # Remove the "data:image/jpeg;base64," prefix if it exists
        if image_data_b64.startswith('data:image/'):
            image_data_b64 = image_data_b64.split(',')[1]

        # Ollama API endpoint for chat completions
        ollama_chat_url = f"{OLLAMA_API_BASE_URL}/generate"

        # Prepare payload for Ollama
        # Note: Ollama's /generate endpoint typically takes images as a list of base64 strings
        payload = {
            "model": OLLAMA_MODEL,
            "prompt": user_query,
            "images": [image_data_b64], # Pass the base64 image here
            "stream": False # Set to True if you want streaming responses
        }

        app.logger.info(f"Sending request to Ollama: {ollama_chat_url} with model {OLLAMA_MODEL}")
        # app.logger.debug(f"Payload: {payload}") # Be careful with logging base64 data in production

        response = requests.post(ollama_chat_url, json=payload, timeout=300) # Added timeout for potentially long LLM responses
        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)
        ollama_response = response.json()

        # Extract the actual response content from Ollama's JSON
        # The structure might vary slightly based on the Ollama version or model,
        # but typically the response content is in ollama_response['response']
        llm_response_content = ollama_response.get('response', 'No response content found.')

        return jsonify({'response': llm_response_content})

    except requests.exceptions.RequestException as e:
        app.logger.error(f"Error connecting to Ollama: {e}")
        return jsonify({'error': f'Failed to connect to Ollama: {e}'}), 500
    except Exception as e:
        app.logger.error(f"An unexpected error occurred: {e}")
        return jsonify({'error': f'An unexpected error occurred: {e}'}), 500

if __name__ == '__main__':
    # Ensure the upload directory exists on startup
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    app.run(debug=True)
